['a', 'b', 'c', '<pad>']
['a', 'c', '<pad>', '<pad>']
['c', 'b', 'c', 'a']

att_mask = [
    [1, 1, 1, 0],
    [1, 1, 0, 0],
    [1, 1, 1, 1]
]


the wind is blowing gently .  ||    th e wi nd is bl ow ing ge nt ly .

jumbled: the is wind blowing gently.    ||  th e is wi nd bl ow ing ge nt ly .


orig: [3, 1, 2, 9, 4]                   [3, 1, 2, 9, 4]
jumbled: [3, 2, 1, 9, 4]                [2, 2, 1, 9, 4]
electra_target: [0, 1, 1, 0, 0]         [1, 1, 1, 0, 0]


#####
OPTION A: shuffle before tokenization
probs:
    (1) lengths of subwords before and after shuffling may differ
    (2) the same subwords may not appear in the subwords for the jumbled sentence
approaches to resolve the issues:
    (1) do not use samples where issue (1) occurs
    (2) accept that the prob of electra loss mask is not equivalent to shuffling prob

OPTION B: shuffle after tokenization
probs:
    (1) we do not want to shuffle on the subword level in the first place!

approaches to resolve the issues:
    (1) after tokenization, we keep track of which word each subword belongs.
        shuffle the subwords now in such a way that the subwords for a word stay together
        even after shuffling.
    (2) accept that the prob of electra loss mask is not equivalent to shuffling prob


# TODO: check that loss is decreasing for mlm training, electra loss training (maybe using tensorboard)
# TODO: check if we can use TPU and speed up training
# TODO: shuffling after tokenization so that subwords for a word remain together


mlm training:
labels = [['a', 'b', 'd', 'c']]   | ids =  [[3, -100, 6, -100]]
inputs = [['<mask>', 'b', '<mask>', 'c']]   |  ids =   [[3, 5, 3, 10]] (3 is mask token id)



batch_size = 2

[[ti_1, tl_1], [ti_2, tl_2]]  ## [t_1, t_2]

[t1, t2]

[2, 3 ,4]  [1, 0, 1]  -> [2, 3, 4, 1, 0, 1]  -> [2, 3, 4, 1, 0, 1, 100, 100] | [2, 3, 4, 100, 1, 0, 1, 100]
[2, 3 ,4, 5]  [1, 0, 1, 0]  -> [2, 3, 4, 5, 1, 0, 1, 0]


[t1, t2, t3, t4]
t1.shape = (2, len(seq))

pad_sequence([t1[0], t2[0], t3[0], t4[0]])
pad_sequence([t1[1], t2[1], t3[1], t4[1]])