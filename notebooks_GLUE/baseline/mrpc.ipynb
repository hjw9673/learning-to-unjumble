{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrpc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYQuspjFWqtJ",
        "colab_type": "text"
      },
      "source": [
        "# Setup working directory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWF9WQibaBPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE91p5EaZXS1",
        "colab_type": "code",
        "outputId": "0c35b9a9-73d8-4f02-f73d-76076cca13df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRJD9PZOWp4X",
        "colab_type": "code",
        "outputId": "c8ef70c5-1003-4306-fdc8-c6f07358949a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "WORKING_DIR=os.path.join('/content', 'drive', 'My Drive', 'Colab Notebooks', 'NLU')\n",
        "os.path.exists(WORKING_DIR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qziRV0mBW060",
        "colab_type": "code",
        "outputId": "71845b09-9fec-493e-fd24-cdc2c500a7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd $WORKING_DIR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmnJe06SfVMN",
        "colab_type": "text"
      },
      "source": [
        "# Clone transformers repo and checkout version 2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rtNjBbdY7RM",
        "colab_type": "code",
        "outputId": "9168f307-181d-4e45-91b0-f83d5258f8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!rm -rf transformers\n",
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 26405 (delta 3), reused 3 (delta 0), pack-reused 26390\u001b[K\n",
            "Receiving objects: 100% (26405/26405), 15.88 MiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (18396/18396), done.\n",
            "Checking out files: 100% (675/675), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU2wFP6SbsZf",
        "colab_type": "code",
        "outputId": "6b1a144c-9378-4693-dfbd-98804f2f620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd transformers/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLU/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LON2QVZObFug",
        "colab_type": "code",
        "outputId": "1cdc7c2a-01a8-4017-fc6d-866ee510b035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!git checkout -f v2.7.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking out files: 100% (474/474), done.\n",
            "Note: checking out 'v2.7.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 6f5a12a5 Release: v2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnSg5LWjfn4w",
        "colab_type": "text"
      },
      "source": [
        "# Install packages required for running `run_glue.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScFAOBb2bRc-",
        "colab_type": "code",
        "outputId": "3ebedfb1-2103-4052-b4bb-0785672326ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r ./examples/requirements.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 3)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 5)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 8)) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r ./examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r ./examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r ./examples/requirements.txt (line 1)) (1.18.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (46.3.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (1.28.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 2)) (1.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r ./examples/requirements.txt (line 4)) (2.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->-r ./examples/requirements.txt (line 6)) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score->-r ./examples/requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (0.3.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (4.41.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (19.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (0.21.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (1.12.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 2)) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 2)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 2)) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 8)) (1.51.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 2)) (0.4.8)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=b936d0e0b5f61938c69df5f1a9c59454a8638f30ec07537c311a7e1927be5d5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboardX, seqeval, portalocker, sacrebleu, rouge-score\n",
            "Successfully installed portalocker-1.7.0 rouge-score-0.0.3 sacrebleu-1.4.9 seqeval-0.0.12 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRsdU00kop7",
        "colab_type": "code",
        "outputId": "f7138481-1e20-4e6e-ce28-24f485688cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "!pip install boto3 filelock requests tqdm sentencepiece sacremoses tokenizers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (1.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 3.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 9.7MB/s \n",
            "\u001b[?25hCollecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3) (1.16.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=aa4fad9e0efc8d0f74fb4b6752494f354b0e7451379c0ec94ebb320c00c168de\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INV4cGxyf2f5",
        "colab_type": "text"
      },
      "source": [
        "# Download GLUE data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWYcFKd9f6Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GLUE_DIR=\"/tmp/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AJp5KgQglVh",
        "colab_type": "code",
        "outputId": "29534747-40f0-4d89-fc23-7b4be4514454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $GLUE_DIR"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24BX_hKwFhdU",
        "colab_type": "code",
        "outputId": "7a65dfa5-ed20-4d53-9088-316f955475d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!python ./utils/download_glue_data.py --help"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: download_glue_data.py [-h] [--data_dir DATA_DIR] [--tasks TASKS]\n",
            "                             [--path_to_mrpc PATH_TO_MRPC]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --data_dir DATA_DIR   directory to save data to\n",
            "  --tasks TASKS         tasks to download data for as a comma separated string\n",
            "  --path_to_mrpc PATH_TO_MRPC\n",
            "                        path to directory containing extracted MRPC data,\n",
            "                        msr_paraphrase_train.txt and msr_paraphrase_text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqf1Fe6cZvI",
        "colab_type": "code",
        "outputId": "bd341498-0987-4869-93bc-861efe779e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!python ./utils/download_glue_data.py --data_dir $GLUE_DIR --tasks MRPC"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing MRPC...\n",
            "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aqkcWzfgFNI",
        "colab_type": "text"
      },
      "source": [
        "# Compute RoBERTa score on MRPC task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFhfVflFdaVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASK_NAME=\"MRPC\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_1EtLRQ8-WF",
        "colab_type": "code",
        "outputId": "56164401-cfab-4f57-eece-7abe276c9603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $TASK_NAME"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MRPC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_9qkZrE8xgk",
        "colab_type": "code",
        "outputId": "b5429403-9f5a-41c5-c525-fbeed4472577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szrKUidsj9kJ",
        "colab_type": "code",
        "outputId": "c7d61634-81f4-429b-f3f9-0b6dd948d7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%set_env PYTHONPATH=$WORKING_DIR/transformers/src:/env/python"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/drive/My Drive/Colab Notebooks/NLU/transformers/src:/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YoNLeB9kNi4",
        "colab_type": "code",
        "outputId": "77a83c6e-e6b6-43fe-f809-06e3e78e4ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLU/transformers/src:/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUEfsVsjXVlC",
        "colab_type": "code",
        "outputId": "3df2bacc-f2ef-4376-e723-066b8b52802e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MODEL_DIR = os.path.join('/content', 'drive', 'My Drive', 'Colab Notebooks', 'NLU', 'models', 'baseline')\n",
        "os.path.exists(MODEL_DIR)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnxryCpnczcm",
        "colab_type": "code",
        "outputId": "ca9d0091-6308-4a54-e3db-ef604b0287c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./examples/run_glue.py \\\n",
        "    --model_type roberta \\\n",
        "    --model_name_or_path /content/drive/My\\ Drive/Colab\\ Notebooks/NLU/models/baseline \\\n",
        "    --task_name $TASK_NAME \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir $GLUE_DIR/$TASK_NAME \\\n",
        "    --max_seq_length 128 \\\n",
        "    --per_gpu_eval_batch_size=64   \\\n",
        "    --per_gpu_train_batch_size=64   \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --output_dir glue_model \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-15 16:40:50.667376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/15/2020 16:40:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/15/2020 16:40:55 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/config.json\n",
            "05/15/2020 16:40:55 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForTokenDiscrimination\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:40:55 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/config.json\n",
            "05/15/2020 16:40:55 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForTokenDiscrimination\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Colab Notebooks/NLU/models/baseline' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/content/drive/My Drive/Colab Notebooks/NLU/models/baseline' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/added_tokens.json. We won't load it.\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/vocab.json\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/merges.txt\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/special_tokens_map.json\n",
            "05/15/2020 16:40:55 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/tokenizer_config.json\n",
            "05/15/2020 16:40:57 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Colab Notebooks/NLU/models/baseline/pytorch_model.bin\n",
            "05/15/2020 16:41:09 - INFO - transformers.modeling_utils -   Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "05/15/2020 16:41:09 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in RobertaForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "05/15/2020 16:41:23 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/tmp/data/MRPC', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='/content/drive/My Drive/Colab Notebooks/NLU/models/baseline', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='glue_model', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, save_steps=500, seed=42, server_ip='', server_port='', task_name='mrpc', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "05/15/2020 16:41:23 - INFO - __main__ -   Creating features from dataset file at /tmp/data/MRPC\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   LOOKING AT /tmp/data/MRPC/train.tsv\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   Writing example 0/3668\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   input_ids: 0 1918 1001 6182 1238 39 2138 2156 2661 37 373 22 5 4562 22 2156 9 12507 7018 23817 39 1283 479 2 2 24551 4506 7 123 25 129 22 5 4562 22 2156 1918 1001 6182 1238 39 2138 9 12507 7018 23817 39 1283 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   input_ids: 0 854 26802 1588 102 2164 13976 1758 128 29 137 2183 5 3206 7 11881 10564 11 6708 13 68 132 4 245 325 479 2 2 854 26802 1588 102 2162 13976 1758 128 29 11 7969 13 68 231 6478 153 8 1088 24 7 11881 10564 13 68 112 4 398 325 11 6708 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   input_ids: 0 252 56 1027 41 6859 15 5 3742 15 502 158 2156 1839 5 9145 13 1392 2156 37 355 479 2 2 374 502 158 2156 5 3627 128 29 2203 56 1027 41 6859 15 5 3742 2156 1839 5 16174 13 1392 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   input_ids: 0 8582 321 28020 5050 2156 12765 327 58 62 753 3205 2156 50 204 4 306 7606 2156 23 83 68 204 4 4419 2156 519 656 278 10 638 239 9 83 68 204 4 4390 479 2 2 12765 327 4262 291 3205 2156 50 204 4 401 7606 2156 7 278 10 638 3172 239 23 83 68 204 4 4390 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   input_ids: 0 20 388 1458 68 132 4 1225 2156 50 59 365 135 2156 7 593 273 23 68 733 4 4708 15 5 188 469 3412 3080 479 2 2 14499 359 381 1913 4 327 4262 68 112 4 5449 50 290 135 7 68 733 4 3933 15 5 188 469 3412 3080 15 273 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:41:23 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/15/2020 16:41:25 - INFO - __main__ -   Saving features into cached file /tmp/data/MRPC/cached_train_baseline_128_mrpc\n",
            "05/15/2020 16:41:26 - INFO - __main__ -   ***** Running training *****\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Num examples = 3668\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Num Epochs = 3\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Total optimization steps = 174\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Continuing training from epoch 0\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Continuing training from global step 0\n",
            "05/15/2020 16:41:26 - INFO - __main__ -     Will skip the first 0 steps in the first epoch\n",
            "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/58 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "\n",
            "Iteration:   2% 1/58 [00:02<02:45,  2.91s/it]\u001b[A\n",
            "Iteration:   3% 2/58 [00:05<02:36,  2.79s/it]\u001b[A\n",
            "Iteration:   5% 3/58 [00:07<02:28,  2.70s/it]\u001b[A\n",
            "Iteration:   7% 4/58 [00:10<02:22,  2.64s/it]\u001b[A\n",
            "Iteration:   9% 5/58 [00:12<02:17,  2.60s/it]\u001b[A\n",
            "Iteration:  10% 6/58 [00:15<02:13,  2.58s/it]\u001b[A\n",
            "Iteration:  12% 7/58 [00:17<02:10,  2.56s/it]\u001b[A\n",
            "Iteration:  14% 8/58 [00:20<02:07,  2.54s/it]\u001b[A\n",
            "Iteration:  16% 9/58 [00:22<02:03,  2.53s/it]\u001b[A\n",
            "Iteration:  17% 10/58 [00:25<02:01,  2.52s/it]\u001b[A\n",
            "Iteration:  19% 11/58 [00:27<01:58,  2.52s/it]\u001b[A\n",
            "Iteration:  21% 12/58 [00:30<01:55,  2.51s/it]\u001b[A\n",
            "Iteration:  22% 13/58 [00:32<01:52,  2.51s/it]\u001b[A\n",
            "Iteration:  24% 14/58 [00:35<01:50,  2.50s/it]\u001b[A\n",
            "Iteration:  26% 15/58 [00:37<01:47,  2.50s/it]\u001b[A\n",
            "Iteration:  28% 16/58 [00:40<01:44,  2.49s/it]\u001b[A\n",
            "Iteration:  29% 17/58 [00:42<01:42,  2.49s/it]\u001b[A\n",
            "Iteration:  31% 18/58 [00:45<01:39,  2.49s/it]\u001b[A\n",
            "Iteration:  33% 19/58 [00:47<01:37,  2.49s/it]\u001b[A\n",
            "Iteration:  34% 20/58 [00:50<01:34,  2.49s/it]\u001b[A\n",
            "Iteration:  36% 21/58 [00:52<01:31,  2.48s/it]\u001b[A\n",
            "Iteration:  38% 22/58 [00:55<01:29,  2.49s/it]\u001b[A\n",
            "Iteration:  40% 23/58 [00:57<01:27,  2.49s/it]\u001b[A\n",
            "Iteration:  41% 24/58 [01:00<01:24,  2.49s/it]\u001b[A\n",
            "Iteration:  43% 25/58 [01:02<01:22,  2.49s/it]\u001b[A\n",
            "Iteration:  45% 26/58 [01:05<01:19,  2.49s/it]\u001b[A\n",
            "Iteration:  47% 27/58 [01:07<01:17,  2.49s/it]\u001b[A\n",
            "Iteration:  48% 28/58 [01:10<01:14,  2.49s/it]\u001b[A\n",
            "Iteration:  50% 29/58 [01:12<01:12,  2.49s/it]\u001b[A\n",
            "Iteration:  52% 30/58 [01:15<01:09,  2.50s/it]\u001b[A\n",
            "Iteration:  53% 31/58 [01:17<01:07,  2.50s/it]\u001b[A\n",
            "Iteration:  55% 32/58 [01:20<01:04,  2.50s/it]\u001b[A\n",
            "Iteration:  57% 33/58 [01:22<01:02,  2.50s/it]\u001b[A\n",
            "Iteration:  59% 34/58 [01:25<00:59,  2.49s/it]\u001b[A\n",
            "Iteration:  60% 35/58 [01:27<00:57,  2.49s/it]\u001b[A\n",
            "Iteration:  62% 36/58 [01:30<00:54,  2.49s/it]\u001b[A\n",
            "Iteration:  64% 37/58 [01:32<00:52,  2.49s/it]\u001b[A\n",
            "Iteration:  66% 38/58 [01:35<00:49,  2.49s/it]\u001b[A\n",
            "Iteration:  67% 39/58 [01:37<00:47,  2.48s/it]\u001b[A\n",
            "Iteration:  69% 40/58 [01:40<00:44,  2.48s/it]\u001b[A\n",
            "Iteration:  71% 41/58 [01:42<00:42,  2.48s/it]\u001b[A\n",
            "Iteration:  72% 42/58 [01:45<00:39,  2.48s/it]\u001b[A\n",
            "Iteration:  74% 43/58 [01:47<00:37,  2.48s/it]\u001b[A\n",
            "Iteration:  76% 44/58 [01:50<00:34,  2.49s/it]\u001b[A\n",
            "Iteration:  78% 45/58 [01:52<00:32,  2.49s/it]\u001b[A\n",
            "Iteration:  79% 46/58 [01:55<00:29,  2.49s/it]\u001b[A\n",
            "Iteration:  81% 47/58 [01:57<00:27,  2.49s/it]\u001b[A\n",
            "Iteration:  83% 48/58 [02:00<00:24,  2.49s/it]\u001b[A\n",
            "Iteration:  84% 49/58 [02:02<00:22,  2.49s/it]\u001b[A\n",
            "Iteration:  86% 50/58 [02:05<00:19,  2.49s/it]\u001b[A\n",
            "Iteration:  88% 51/58 [02:07<00:17,  2.48s/it]\u001b[A\n",
            "Iteration:  90% 52/58 [02:10<00:14,  2.48s/it]\u001b[A\n",
            "Iteration:  91% 53/58 [02:12<00:12,  2.49s/it]\u001b[A\n",
            "Iteration:  93% 54/58 [02:14<00:09,  2.49s/it]\u001b[A\n",
            "Iteration:  95% 55/58 [02:17<00:07,  2.49s/it]\u001b[A\n",
            "Iteration:  97% 56/58 [02:19<00:04,  2.49s/it]\u001b[A\n",
            "Iteration:  98% 57/58 [02:22<00:02,  2.49s/it]\u001b[A\n",
            "Iteration: 100% 58/58 [02:23<00:00,  2.47s/it]\n",
            "Epoch:  33% 1/3 [02:23<04:46, 143.32s/it]\n",
            "Iteration:   0% 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/58 [00:02<02:21,  2.49s/it]\u001b[A\n",
            "Iteration:   3% 2/58 [00:04<02:19,  2.49s/it]\u001b[A\n",
            "Iteration:   5% 3/58 [00:07<02:16,  2.48s/it]\u001b[A\n",
            "Iteration:   7% 4/58 [00:09<02:14,  2.49s/it]\u001b[A\n",
            "Iteration:   9% 5/58 [00:12<02:11,  2.49s/it]\u001b[A\n",
            "Iteration:  10% 6/58 [00:14<02:09,  2.49s/it]\u001b[A\n",
            "Iteration:  12% 7/58 [00:17<02:07,  2.49s/it]\u001b[A\n",
            "Iteration:  14% 8/58 [00:19<02:04,  2.49s/it]\u001b[A\n",
            "Iteration:  16% 9/58 [00:22<02:02,  2.49s/it]\u001b[A\n",
            "Iteration:  17% 10/58 [00:24<01:59,  2.49s/it]\u001b[A\n",
            "Iteration:  19% 11/58 [00:27<01:57,  2.49s/it]\u001b[A\n",
            "Iteration:  21% 12/58 [00:29<01:54,  2.49s/it]\u001b[A\n",
            "Iteration:  22% 13/58 [00:32<01:52,  2.49s/it]\u001b[A\n",
            "Iteration:  24% 14/58 [00:34<01:49,  2.49s/it]\u001b[A\n",
            "Iteration:  26% 15/58 [00:37<01:47,  2.49s/it]\u001b[A\n",
            "Iteration:  28% 16/58 [00:39<01:44,  2.49s/it]\u001b[A\n",
            "Iteration:  29% 17/58 [00:42<01:41,  2.49s/it]\u001b[A\n",
            "Iteration:  31% 18/58 [00:44<01:39,  2.48s/it]\u001b[A\n",
            "Iteration:  33% 19/58 [00:47<01:36,  2.48s/it]\u001b[A\n",
            "Iteration:  34% 20/58 [00:49<01:34,  2.48s/it]\u001b[A\n",
            "Iteration:  36% 21/58 [00:52<01:31,  2.49s/it]\u001b[A\n",
            "Iteration:  38% 22/58 [00:54<01:29,  2.48s/it]\u001b[A\n",
            "Iteration:  40% 23/58 [00:57<01:27,  2.49s/it]\u001b[A\n",
            "Iteration:  41% 24/58 [00:59<01:24,  2.49s/it]\u001b[A\n",
            "Iteration:  43% 25/58 [01:02<01:22,  2.49s/it]\u001b[A\n",
            "Iteration:  45% 26/58 [01:04<01:19,  2.49s/it]\u001b[A\n",
            "Iteration:  47% 27/58 [01:07<01:17,  2.49s/it]\u001b[A\n",
            "Iteration:  48% 28/58 [01:09<01:14,  2.49s/it]\u001b[A\n",
            "Iteration:  50% 29/58 [01:12<01:12,  2.49s/it]\u001b[A\n",
            "Iteration:  52% 30/58 [01:14<01:09,  2.49s/it]\u001b[A\n",
            "Iteration:  53% 31/58 [01:17<01:07,  2.49s/it]\u001b[A\n",
            "Iteration:  55% 32/58 [01:19<01:04,  2.49s/it]\u001b[A\n",
            "Iteration:  57% 33/58 [01:22<01:02,  2.49s/it]\u001b[A\n",
            "Iteration:  59% 34/58 [01:24<00:59,  2.49s/it]\u001b[A\n",
            "Iteration:  60% 35/58 [01:27<00:57,  2.49s/it]\u001b[A\n",
            "Iteration:  62% 36/58 [01:29<00:54,  2.48s/it]\u001b[A\n",
            "Iteration:  64% 37/58 [01:32<00:52,  2.48s/it]\u001b[A\n",
            "Iteration:  66% 38/58 [01:34<00:49,  2.49s/it]\u001b[A\n",
            "Iteration:  67% 39/58 [01:37<00:47,  2.49s/it]\u001b[A\n",
            "Iteration:  69% 40/58 [01:39<00:44,  2.48s/it]\u001b[A\n",
            "Iteration:  71% 41/58 [01:42<00:42,  2.49s/it]\u001b[A\n",
            "Iteration:  72% 42/58 [01:44<00:39,  2.49s/it]\u001b[A\n",
            "Iteration:  74% 43/58 [01:46<00:37,  2.49s/it]\u001b[A\n",
            "Iteration:  76% 44/58 [01:49<00:34,  2.49s/it]\u001b[A\n",
            "Iteration:  78% 45/58 [01:51<00:32,  2.49s/it]\u001b[A\n",
            "Iteration:  79% 46/58 [01:54<00:29,  2.49s/it]\u001b[A\n",
            "Iteration:  81% 47/58 [01:56<00:27,  2.49s/it]\u001b[A\n",
            "Iteration:  83% 48/58 [01:59<00:24,  2.49s/it]\u001b[A\n",
            "Iteration:  84% 49/58 [02:01<00:22,  2.49s/it]\u001b[A\n",
            "Iteration:  86% 50/58 [02:04<00:19,  2.49s/it]\u001b[A\n",
            "Iteration:  88% 51/58 [02:06<00:17,  2.49s/it]\u001b[A\n",
            "Iteration:  90% 52/58 [02:09<00:14,  2.49s/it]\u001b[A\n",
            "Iteration:  91% 53/58 [02:11<00:12,  2.49s/it]\u001b[A\n",
            "Iteration:  93% 54/58 [02:14<00:09,  2.49s/it]\u001b[A\n",
            "Iteration:  95% 55/58 [02:16<00:07,  2.49s/it]\u001b[A\n",
            "Iteration:  97% 56/58 [02:19<00:04,  2.49s/it]\u001b[A\n",
            "Iteration:  98% 57/58 [02:21<00:02,  2.49s/it]\u001b[A\n",
            "Iteration: 100% 58/58 [02:22<00:00,  2.46s/it]\n",
            "Epoch:  67% 2/3 [04:46<02:23, 143.14s/it]\n",
            "Iteration:   0% 0/58 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/58 [00:02<02:21,  2.48s/it]\u001b[A\n",
            "Iteration:   3% 2/58 [00:04<02:18,  2.48s/it]\u001b[A\n",
            "Iteration:   5% 3/58 [00:07<02:16,  2.49s/it]\u001b[A\n",
            "Iteration:   7% 4/58 [00:09<02:14,  2.49s/it]\u001b[A\n",
            "Iteration:   9% 5/58 [00:12<02:11,  2.49s/it]\u001b[A\n",
            "Iteration:  10% 6/58 [00:14<02:09,  2.49s/it]\u001b[A\n",
            "Iteration:  12% 7/58 [00:17<02:06,  2.49s/it]\u001b[A\n",
            "Iteration:  14% 8/58 [00:19<02:04,  2.49s/it]\u001b[A\n",
            "Iteration:  16% 9/58 [00:22<02:01,  2.49s/it]\u001b[A\n",
            "Iteration:  17% 10/58 [00:24<01:59,  2.49s/it]\u001b[A\n",
            "Iteration:  19% 11/58 [00:27<01:57,  2.49s/it]\u001b[A\n",
            "Iteration:  21% 12/58 [00:29<01:54,  2.49s/it]\u001b[A\n",
            "Iteration:  22% 13/58 [00:32<01:52,  2.49s/it]\u001b[A\n",
            "Iteration:  24% 14/58 [00:34<01:49,  2.49s/it]\u001b[A\n",
            "Iteration:  26% 15/58 [00:37<01:46,  2.49s/it]\u001b[A\n",
            "Iteration:  28% 16/58 [00:39<01:44,  2.49s/it]\u001b[A\n",
            "Iteration:  29% 17/58 [00:42<01:41,  2.48s/it]\u001b[A\n",
            "Iteration:  31% 18/58 [00:44<01:39,  2.48s/it]\u001b[A\n",
            "Iteration:  33% 19/58 [00:47<01:36,  2.48s/it]\u001b[A\n",
            "Iteration:  34% 20/58 [00:49<01:34,  2.48s/it]\u001b[A\n",
            "Iteration:  36% 21/58 [00:52<01:32,  2.49s/it]\u001b[A\n",
            "Iteration:  38% 22/58 [00:54<01:29,  2.49s/it]\u001b[A\n",
            "Iteration:  40% 23/58 [00:57<01:27,  2.49s/it]\u001b[A\n",
            "Iteration:  41% 24/58 [00:59<01:24,  2.49s/it]\u001b[A\n",
            "Iteration:  43% 25/58 [01:02<01:22,  2.49s/it]\u001b[A\n",
            "Iteration:  45% 26/58 [01:04<01:19,  2.49s/it]\u001b[A\n",
            "Iteration:  47% 27/58 [01:07<01:17,  2.50s/it]\u001b[A\n",
            "Iteration:  48% 28/58 [01:09<01:14,  2.49s/it]\u001b[A\n",
            "Iteration:  50% 29/58 [01:12<01:12,  2.49s/it]\u001b[A\n",
            "Iteration:  52% 30/58 [01:14<01:09,  2.49s/it]\u001b[A\n",
            "Iteration:  53% 31/58 [01:17<01:07,  2.49s/it]\u001b[A\n",
            "Iteration:  55% 32/58 [01:19<01:04,  2.48s/it]\u001b[A\n",
            "Iteration:  57% 33/58 [01:22<01:02,  2.48s/it]\u001b[A\n",
            "Iteration:  59% 34/58 [01:24<00:59,  2.48s/it]\u001b[A\n",
            "Iteration:  60% 35/58 [01:27<00:57,  2.48s/it]\u001b[A\n",
            "Iteration:  62% 36/58 [01:29<00:54,  2.48s/it]\u001b[A\n",
            "Iteration:  64% 37/58 [01:32<00:52,  2.48s/it]\u001b[A\n",
            "Iteration:  66% 38/58 [01:34<00:49,  2.49s/it]\u001b[A\n",
            "Iteration:  67% 39/58 [01:36<00:47,  2.49s/it]\u001b[A\n",
            "Iteration:  69% 40/58 [01:39<00:44,  2.49s/it]\u001b[A\n",
            "Iteration:  71% 41/58 [01:41<00:42,  2.49s/it]\u001b[A\n",
            "Iteration:  72% 42/58 [01:44<00:39,  2.48s/it]\u001b[A\n",
            "Iteration:  74% 43/58 [01:46<00:37,  2.49s/it]\u001b[A\n",
            "Iteration:  76% 44/58 [01:49<00:34,  2.48s/it]\u001b[A\n",
            "Iteration:  78% 45/58 [01:51<00:32,  2.48s/it]\u001b[A\n",
            "Iteration:  79% 46/58 [01:54<00:29,  2.48s/it]\u001b[A\n",
            "Iteration:  81% 47/58 [01:56<00:27,  2.49s/it]\u001b[A\n",
            "Iteration:  83% 48/58 [01:59<00:24,  2.49s/it]\u001b[A\n",
            "Iteration:  84% 49/58 [02:01<00:22,  2.49s/it]\u001b[A\n",
            "Iteration:  86% 50/58 [02:04<00:19,  2.49s/it]\u001b[A\n",
            "Iteration:  88% 51/58 [02:06<00:17,  2.49s/it]\u001b[A\n",
            "Iteration:  90% 52/58 [02:09<00:14,  2.49s/it]\u001b[A\n",
            "Iteration:  91% 53/58 [02:11<00:12,  2.49s/it]\u001b[A\n",
            "Iteration:  93% 54/58 [02:14<00:09,  2.49s/it]\u001b[A\n",
            "Iteration:  95% 55/58 [02:16<00:07,  2.49s/it]\u001b[A\n",
            "Iteration:  97% 56/58 [02:19<00:04,  2.49s/it]\u001b[A\n",
            "Iteration:  98% 57/58 [02:21<00:02,  2.49s/it]\u001b[A\n",
            "Iteration: 100% 58/58 [02:22<00:00,  2.46s/it]\n",
            "Epoch: 100% 3/3 [07:08<00:00, 142.89s/it]\n",
            "05/15/2020 16:48:35 - INFO - __main__ -    global_step = 174, average loss = 0.5748786842343451\n",
            "05/15/2020 16:48:35 - INFO - __main__ -   Saving model checkpoint to glue_model\n",
            "05/15/2020 16:48:35 - INFO - transformers.configuration_utils -   Configuration saved in glue_model/config.json\n",
            "05/15/2020 16:48:37 - INFO - transformers.modeling_utils -   Model weights saved in glue_model/pytorch_model.bin\n",
            "05/15/2020 16:48:37 - INFO - transformers.configuration_utils -   loading configuration file glue_model/config.json\n",
            "05/15/2020 16:48:37 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:48:37 - INFO - transformers.modeling_utils -   loading weights file glue_model/pytorch_model.bin\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   loading configuration file glue_model/config.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   Model name 'glue_model' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'glue_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   Didn't find file glue_model/added_tokens.json. We won't load it.\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/vocab.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/merges.txt\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/special_tokens_map.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/tokenizer_config.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   loading configuration file glue_model/config.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   Model name 'glue_model' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'glue_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   Didn't find file glue_model/added_tokens.json. We won't load it.\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/vocab.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/merges.txt\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/special_tokens_map.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.tokenization_utils -   loading file glue_model/tokenizer_config.json\n",
            "05/15/2020 16:48:43 - INFO - __main__ -   Evaluate the following checkpoints: ['glue_model']\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   loading configuration file glue_model/config.json\n",
            "05/15/2020 16:48:43 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/15/2020 16:48:43 - INFO - transformers.modeling_utils -   loading weights file glue_model/pytorch_model.bin\n",
            "05/15/2020 16:48:51 - INFO - __main__ -   Creating features from dataset file at /tmp/data/MRPC\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   Writing example 0/408\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   input_ids: 0 91 26 5 689 11131 11637 265 630 128 90 2564 5 138 128 29 251 12 1279 434 1860 479 2 2 22 20 689 11131 11637 265 473 45 2564 84 251 12 1279 434 1860 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   input_ids: 0 15683 1322 10054 26 14822 636 1242 19975 5 7780 4304 8 1415 556 7 634 39 251 107 9 1058 11 5 997 479 2 2 832 1141 26 37 21 22 727 135 639 1655 3516 22 8 1415 556 7 634 39 107 9 1058 11 5 997 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   input_ids: 0 20 1404 21 23 15966 4 6617 4796 136 5 4796 2156 3269 15 5 1852 2156 8 23 112 4 2517 6468 136 5 5092 13638 2156 67 3269 479 2 2 20 1404 21 23 15966 4 5479 4796 14621 975 5457 2156 8077 3269 15 5 1852 2156 8 23 112 4 2517 5339 136 5 5092 13638 3858 597 5457 2156 159 321 4 134 135 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   input_ids: 0 20 16305 12 347 6454 16 2445 454 779 7 2845 114 24 40 18839 10 1984 479 2 2 20 16305 12 347 6454 585 307 14 24 40 2845 11 779 549 7 18839 10 1984 137 5 19050 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   input_ids: 0 440 5461 33 57 278 13 5 2366 50 5 1837 1500 479 2 2 440 5461 33 57 278 13 5 1837 50 2366 1200 2156 53 18966 607 34 4407 45 2181 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 16:48:51 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/15/2020 16:48:51 - INFO - __main__ -   Saving features into cached file /tmp/data/MRPC/cached_dev_baseline_128_mrpc\n",
            "05/15/2020 16:48:51 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "05/15/2020 16:48:51 - INFO - __main__ -     Num examples = 408\n",
            "05/15/2020 16:48:51 - INFO - __main__ -     Batch size = 64\n",
            "Evaluating: 100% 7/7 [00:05<00:00,  1.20it/s]\n",
            "05/15/2020 16:48:57 - INFO - __main__ -   ***** Eval results  *****\n",
            "05/15/2020 16:48:57 - INFO - __main__ -     acc = 0.8063725490196079\n",
            "05/15/2020 16:48:57 - INFO - __main__ -     acc_and_f1 = 0.8376804701980294\n",
            "05/15/2020 16:48:57 - INFO - __main__ -     f1 = 0.868988391376451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdGtUfYNRu8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}